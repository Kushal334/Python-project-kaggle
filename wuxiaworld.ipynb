{
 "metadata": {
  "name": "",
  "signature": "sha256:bd23495dc9000410652ca09fac94d655889c364c49a6f63aacb64f6037d34aa5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wuxiaworld Web Scrapper - Convert Translated Chinese Novels from HTML to PDF\n",
      "\n",
      "I tend to read lots of translated chinese novel from this site. But it requires internet connection, as each chapter is a HTML page. I want to scrap the chapters from the website and convert to pdf, so that I can read them offline\n",
      "\n",
      "## How am I going to do it?\n",
      "\n",
      "I am planning to use 'requests' and 'beautifulsoup4' to write a python webscrapper"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests as rq # To get html of webpage as string\n",
      "from bs4 import BeautifulSoup as bs # To parse HTML string into a DOM\n",
      "from IPython.core.display import display, HTML # For pretty HTML output in ipython\n",
      "from urllib.parse import urlparse, urljoin # For easy parsing of url\n",
      "import subprocess\n",
      "import pdfkit\n",
      "import time\n",
      "import numpy as np\n",
      "from PyPDF2 import PdfFileReader, PdfFileMerger\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weburl = \"http://www.wuxiaworld.com/\" # Url of the website I am going to scrap\n",
      "r = rq.get(weburl)\n",
      "display ( r.status_code, r.encoding, r.url )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "200"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'UTF-8'"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'http://www.wuxiaworld.com/'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = bs(r.text, \"lxml\")\n",
      "title = soup.title\n",
      "display ( title.text )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'Wuxiaworld \u2013 Chinese fantasy novels and light novels!'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab all links in navbar and remove anchor links\n",
      "aLink = [ \n",
      "    ( link.attrs[\"href\"], link.text ) \n",
      "    for link in soup.select('nav a') \n",
      "    if link.attrs[\"href\"].startswith(\"#\") == False\n",
      "]\n",
      "\n",
      "# Links towards the end are not related to chinese novels, so slice them up\n",
      "novelList = [ \n",
      "    ( urlparse(link).path, name ) \n",
      "    for ( link, name ) in aLink \n",
      "][1:-15]\n",
      "\n",
      "display ( list ( enumerate ( novelList ) ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "[(0, ('/7-killers/', '7 Killers (\u4e03\u6740\u624b)')),\n",
        " (1, ('/col-index/', 'Child of Light (\u5149\u4e4b\u5b50)')),\n",
        " (2, ('/cdindex-html/', 'Coiling Dragon (\u76d8\u9f99)')),\n",
        " (3, ('/dkwss/', 'Dragon King With Seven Stars (\u4e03\u661f\u9f99\u738b)')),\n",
        " (4, ('/hsnt-index/', 'Heroes Shed No Tears (\u82f1\u96c4\u4e0d\u6d41\u6cea)')),\n",
        " (5, ('/tymyd-index/', 'Horizon, Bright Moon, Sabre (\u5929\u6daf\u660e\u6708\u5200)')),\n",
        " (6, ('/st-index/', 'Stellar Transformations (\u661f\u8fb0\u53d8)')),\n",
        " (7, ('/absolute-choice-index/', 'Absolute Choice (\u7edd\u5bf9\u9009\u9879)')),\n",
        " (8, ('/atg-index/', 'Against the Gods (\u9006\u5929\u90aa\u795e)')),\n",
        " (9, ('/awe-index/', 'A Will Eternal (\u4e00\u5ff5\u6c38\u6052)')),\n",
        " (10, ('/btth-index/', 'Battle Through the Heavens (\u6597\u7834\u82cd\u7a79)')),\n",
        " (11, ('/desolate-era-index/', 'Desolate Era (\u83bd\u8352\u7eaa)')),\n",
        " (12, ('/emperor-index/', 'Emperor\u2019s Domination (\u5e1d\u9738)')),\n",
        " (13, ('/gor-index/', 'Gate of Revelation (\u5929\u542f\u4e4b\u95e8)')),\n",
        " (14, ('/hjc-index/', 'Heavenly Jewel Change (\u5929\u73e0\u53d8)')),\n",
        " (15, ('/issth-index/', 'I Shall Seal the Heavens (\u6211\u6b32\u5c01\u5929)')),\n",
        " (16, ('/ldk-index/', 'Legend of the Dragon King (\u9f99\u738b\u4f20\u8bf4)')),\n",
        " (17, ('/mga-index/', 'Martial God Asura (\u4fee\u7f57\u6b66\u795e)')),\n",
        " (18, ('/pw-index/', 'Perfect World (\u5b8c\u7f8e\u4e16\u754c)')),\n",
        " (19, ('/rebirth-index/', 'Rebirth of the Thief')),\n",
        " (20, ('/renegade-index/', 'Renegade Immortal (\u4ed9\u9006)')),\n",
        " (21, ('/sfl-index/', 'Skyfire Avenue (\u5929\u706b\u5927\u9053)')),\n",
        " (22, ('/sotr-index/', 'Sovereign of the Three Realms (\u4e09\u754c\u72ec\u5c0a)')),\n",
        " (23, ('/sr-index/', 'Spirit Realm (\u7075\u57df)')),\n",
        " (24, ('/tdg-index/', 'Tales of Demons & Gods (\u5996\u795e\u8bb0)')),\n",
        " (25, ('/ti-index/', 'Terror Infinity (\u65e0\u9650\u6050\u6016)')),\n",
        " (26, ('/tgr-index/', 'The Great Ruler (\u5927\u4e3b\u5bb0)')),\n",
        " (27, ('/usaw-index/', 'Upgrade Specialist in Another World')),\n",
        " (28, ('/wmw-index/', 'Warlock of the Magus World (\u5deb\u754c\u672f\u58eb)')),\n",
        " (29, ('/wdqk-index/', 'Wu Dong Qian Kun (\u6b66\u52a8\u4e7e\u5764)'))]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a novelList, let's try to process just one of the novel. If we can scrap one novel, we can scrap them all.\n",
      "\n",
      "## Scraping A Single Novel\n",
      "\n",
      "Each novel will have a seperate folder, with folders having name in `<url-nick>-<name>` format.\n",
      "\n",
      "Inside the folder, we will have a info.html file that will have it's info page in it.\n",
      "\n",
      "Next we will have a file info.clean.html, that will have the same page, but with unnecessary tags removed, like comments and ads.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdfOptions = { 'encoding': \"UTF-8\" }\n",
      "\n",
      "def replaceNonAsciiWith(text, replacement):\n",
      "    return ''.join([i if ord(i) < 128 else replacement for i in text])\n",
      "\n",
      "def uniq(seq):\n",
      "    seen = set()\n",
      "    seen_add = seen.add\n",
      "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
      "\n",
      "def fileNameSafe(s):\n",
      "    keepcharacters = (' ','.','_','-')\n",
      "    return \"\".join(c for c in s if c.isalnum() or c in keepcharacters).rstrip()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convertNovelToPdf( novelNickUrl, novelName ):\n",
      "    novelUrl = urljoin(weburl,novelNickUrl)\n",
      "    print( \"Processing Novel: {} with url {}\".format( novelName, novelUrl) )\n",
      "    novelrq = rq.get(novelUrl)\n",
      "    novelSoup = bs(novelrq.text, \"lxml\")\n",
      "    \n",
      "    article = novelSoup.find('article')\n",
      "    \n",
      "    # Create a folder to store this novel\n",
      "    folderName = fileNameSafe(novelNickUrl)\n",
      "    subprocess.call( \"mkdir -p {}\".format(folderName), shell=True )\n",
      "    \n",
      "    # Grab information about the novel and save it to pdf\n",
      "    pdfkit.from_string(article.prettify(), \"info.pdf\", pdfOptions)\n",
      "    subprocess.call( \"mv {} {}\".format(\"info.pdf\", folderName + \"/info.pdf\" ), shell=True )\n",
      "    \n",
      "    # Grab chapter list from info page\n",
      "    novelChapters = [ \n",
      "        (link.attrs['href'], fileNameSafe ( urlparse(link.attrs['href'])[2] ) ) \n",
      "        for link in article.select('a') \n",
      "        if folderName in link.attrs['href']\n",
      "    ]\n",
      "    \n",
      "    # Make chapters unique cause I saw some duplicates\n",
      "    novelChapters = uniq(novelChapters)\n",
      "    \n",
      "    # Add XXXXX integer index to each filename\n",
      "    novelChapters = [ \n",
      "        ( pair[0], \"{:05}-{}.pdf\".format(ind,pair[1]) ) \n",
      "        for ind, pair in enumerate( novelChapters ) \n",
      "    ]\n",
      "    \n",
      "    totalChapter = len(novelChapters)\n",
      "    \n",
      "    for chapterUrl, chapterName in novelChapters:\n",
      "        time.sleep(1) # Common courtesy when scrapping website. You don't want to overload the site\n",
      "        crq = rq.get(chapterUrl) # Get the chapter html\n",
      "        csoup = bs(crq.text, \"lxml\") # Parse it\n",
      "        carticle = csoup.find('article').prettify() # Find first article tag and convert to pretty string\n",
      "        pdfkit.from_string(carticle, chapterName, pdfOptions) # Output to pdf\n",
      "        subprocess.call( \"mv {} {}\".format( chapterName, folderName + '/' + chapterName), shell=True )\n",
      "        print ( \"Finished {} out of {}\".format(chapterName, totalChapter) )\n",
      "    \n",
      "    # Now merge those chapters together\n",
      "    print ( \"Starting merger of pdf files\" )\n",
      "    merger = PdfFileMerger()\n",
      "    with open(os.path.join(folderName, 'info.pdf'), 'rb') as f:\n",
      "        merger.append( PdfFileReader(f) )\n",
      "    \n",
      "    for chapterUrl, chapterName in novelChapters:\n",
      "        print ( \"Processing {}\".format(chapterName) )\n",
      "        with open(os.path.join(folderName, chapterName), 'rb') as f:\n",
      "            merger.append( PdfFileReader(f) )\n",
      "    \n",
      "    merger.write(\"output.pdf\")\n",
      "    subprocess.call( \"mv output.pdf {0}/merged-{0}.pdf\".format( folderName), shell=True )    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now I can scrap any novel from novelList. Simply provide the index number\n",
      "novelIndex = 0\n",
      "convertNovelToPdf(novelList[novelIndex][0], novelList[novelIndex][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing Novel: 7 Killers (\u4e03\u6740\u624b) with url http://www.wuxiaworld.com/7-killers/\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n",
        "Finished 00000-master-index7-killers-chapter-1.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00001-master-index7-killers-chapter-2.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00002-master-index7-killers-chapter-3.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00003-master-index7-killers-chapter-4.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00004-master-index7-killers-chapter-5.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00005-master-index7-killers-chapter-6.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00006-master-index7-killers-chapter-7.pdf out of 8\n",
        "Loading page (1/2)\n",
        "[>                                                           ] 0%\r",
        "[======>                                                     ] 10%\r",
        "[==============================>                             ] 50%\r",
        "[============================================================] 100%\r",
        "Printing pages (2/2)                                               \n",
        "[>                                                           ] \r",
        "Done                                                           \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished 00007-master-index7-killers-chapter-8.pdf out of 8\n",
        "Starting merger of pdf files\n",
        "Processing 00000-master-index7-killers-chapter-1.pdf\n",
        "Processing 00001-master-index7-killers-chapter-2.pdf\n",
        "Processing 00002-master-index7-killers-chapter-3.pdf\n",
        "Processing 00003-master-index7-killers-chapter-4.pdf\n",
        "Processing 00004-master-index7-killers-chapter-5.pdf\n",
        "Processing 00005-master-index7-killers-chapter-6.pdf\n",
        "Processing 00006-master-index7-killers-chapter-7.pdf\n",
        "Processing 00007-master-index7-killers-chapter-8.pdf\n"
       ]
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}